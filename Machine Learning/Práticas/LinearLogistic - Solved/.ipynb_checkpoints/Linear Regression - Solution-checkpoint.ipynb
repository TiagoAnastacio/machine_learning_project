{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression\n",
    "\n",
    "Doing a linear regression is, in principle, very simple. We have a set of data points $(x_i, y_i)$ and we want to find a function $f(x)$ that fits the data. The function $f(x)$ is a linear combination of basis functions $\\phi_j(x)$:\n",
    "\n",
    "$$f(x) = w_0 + \\sum_{j=1}^M w_j \\phi_j(x)$$\n",
    "\n",
    "In this course, we cover the class **Linear Regression**, which implies that the function $f(x)$ is linear in the parameters $w_j$. The basis functions $\\phi_j(x)$ can be non-linear, but the overall function is linear in terms of the weights. The hyperplane is obtained using **Ordinary Least Squares (OLS)**, which minimizes the sum of squared differences between the observed values $y_i$ and the values predicted by the model $f(x_i)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "## **Index**<br>\n",
    "\n",
    "[1. **A Simple Example**](#1st-bullet)<br>\n",
    "- [1.1 Create a Small Synthetic Dataset](#2nd-bullet)<br>\n",
    "- [1.2 Fit the Model](#3rd-bullet)<br>\n",
    "- [1.3 Evaluate the Model](#4th-bullet)<br>\n",
    "\n",
    "[2. **Scikit-Learn Implementation**](#5th-bullet)<br>\n",
    "- [2.1 Load a Real Dataset](#6th-bullet)<br>\n",
    "- [2.2 Preprocess the Data](#7th-bullet)<br>\n",
    "- [2.3 Fit the Model](#8th-bullet)<br>\n",
    "- [2.4 Evaluate the Model](#9th-bullet)<br>\n",
    "\n",
    "[3. **Computing p-values**](#10th-bullet)<br>\n",
    "- [3.1 Fit the Model with stastomdels](#11th-bullet)<br>\n",
    "\n",
    "[4. **Extra Material: Linear Regression Variants**](#13th-bullet)<br>\n",
    "- [4.1 Ridge Regression](#14th-bullet)<br>\n",
    "- [4.2 Lasso Regression](#15th-bullet)<br>\n",
    "- [4.3 Elastic Net](#16th-bullet)<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 0`__ - The first thing you should do is always import the needed libraries. In this case, we are going to import:\n",
    "- pandas as pd\n",
    "- numpy as np\n",
    "- LinearRegression from sklearn.linear_model\n",
    "- train_test_split from sklearn.model_selection\n",
    "- matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "\n",
    "np.random.seed(33)  # For reproducibility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **A Simple Example** <a name=\"1st-bullet\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Create a Small Synthetic Dataset <a name=\"2nd-bullet\"></a>\n",
    "\n",
    "We'll create a tiny synthetic dataset (houses) to illustrate ordinary least squares manually. The goal of this short example is to build intuition: compute the slope and intercept by hand using the closed-form formulas. Then, we will use the `LinearRegression` class from `sklearn` ton a larger dataset to see how the implementation works in practice.\n",
    "\n",
    "Follow the steps below to compute the means, deviations and sums that lead to the OLS estimates for a single predictor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">><font color='Orange'> __Practice__ - A 2D example from scratch</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are going to work with the following dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>m^2</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>160</td>\n",
       "      <td>360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>150</td>\n",
       "      <td>340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>280</td>\n",
       "      <td>664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>140</td>\n",
       "      <td>330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>220</td>\n",
       "      <td>560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>130</td>\n",
       "      <td>380</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   m^2  Price\n",
       "0  160    360\n",
       "1  150    340\n",
       "2  280    664\n",
       "3  140    330\n",
       "4  220    560\n",
       "5  130    380"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "houses = pd.DataFrame({'m^2':[160,150,280,140,220,130],'Price':[360,340,664,330,560,380]})\n",
    "houses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Fit the Model <a name=\"3rd-bullet\"></a>\n",
    "\n",
    "Below you will compute the sample means, create deviation columns and use the formula for the slope (beta1) and intercept (beta0). Doing this by hand is a great way to see how each term affects the result before using library routines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's time now to build a step by step a simple linear regression. To calculate the coefficient we are going to use the formula:\n",
    "\n",
    "$$\\beta _{1} = \\frac{\\sum \\left ( x_{i}-\\bar{x})( y_{i}-\\bar{y}\\right )}{\\sum ( x_{i}-\\bar{x})^{2}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the intercept is going to be calculated using the formula:\n",
    "$$\\beta _{0} = \\bar{y} - \\beta _{1}\\bar{x} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Exercise A`__: Try to calculate the regression equation associated to the dataset step by step and predict the value for a house with $190m^{2}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`a.1.`__ Calculate the mean of the values in your X and assign it to the object __mean_m2__. In the same way, calculate the mean of your target and assign it to the object __mean_price__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "180.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_m2 = houses[\"m^2\"].mean()\n",
    "mean_m2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "439.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_price = houses[\"Price\"].mean()\n",
    "mean_price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`a.2`__ Create a new column in your dataset 'houses' named as __xi-x_mean__ that will contain $( x_{i}-\\bar{x})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>m^2</th>\n",
       "      <th>Price</th>\n",
       "      <th>xi-x_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>160</td>\n",
       "      <td>360</td>\n",
       "      <td>-20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>150</td>\n",
       "      <td>340</td>\n",
       "      <td>-30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>280</td>\n",
       "      <td>664</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>140</td>\n",
       "      <td>330</td>\n",
       "      <td>-40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>220</td>\n",
       "      <td>560</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>130</td>\n",
       "      <td>380</td>\n",
       "      <td>-50.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   m^2  Price  xi-x_mean\n",
       "0  160    360      -20.0\n",
       "1  150    340      -30.0\n",
       "2  280    664      100.0\n",
       "3  140    330      -40.0\n",
       "4  220    560       40.0\n",
       "5  130    380      -50.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "houses['xi-x_mean'] = houses[\"m^2\"] - mean_m2\n",
    "houses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`a.3`__ Create a new column in your dataset 'houses' named as __yi-y_mean__ that will contain $( y_{i}-\\bar{y})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>m^2</th>\n",
       "      <th>Price</th>\n",
       "      <th>xi-x_mean</th>\n",
       "      <th>yi-y_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>160</td>\n",
       "      <td>360</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>-79.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>150</td>\n",
       "      <td>340</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>-99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>280</td>\n",
       "      <td>664</td>\n",
       "      <td>100.0</td>\n",
       "      <td>225.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>140</td>\n",
       "      <td>330</td>\n",
       "      <td>-40.0</td>\n",
       "      <td>-109.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>220</td>\n",
       "      <td>560</td>\n",
       "      <td>40.0</td>\n",
       "      <td>121.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>130</td>\n",
       "      <td>380</td>\n",
       "      <td>-50.0</td>\n",
       "      <td>-59.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   m^2  Price  xi-x_mean  yi-y_mean\n",
       "0  160    360      -20.0      -79.0\n",
       "1  150    340      -30.0      -99.0\n",
       "2  280    664      100.0      225.0\n",
       "3  140    330      -40.0     -109.0\n",
       "4  220    560       40.0      121.0\n",
       "5  130    380      -50.0      -59.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "houses['yi-y_mean'] = houses[\"Price\"] - mean_price\n",
    "houses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`a.4`__ Create a new column in your dataset 'houses' named as __square(xi-x_mean)__ that will be equal to $(x_{i}-\\bar{x})^{2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>m^2</th>\n",
       "      <th>Price</th>\n",
       "      <th>xi-x_mean</th>\n",
       "      <th>yi-y_mean</th>\n",
       "      <th>square(xi-x_mean)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>160</td>\n",
       "      <td>360</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>-79.0</td>\n",
       "      <td>400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>150</td>\n",
       "      <td>340</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>900.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>280</td>\n",
       "      <td>664</td>\n",
       "      <td>100.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>10000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>140</td>\n",
       "      <td>330</td>\n",
       "      <td>-40.0</td>\n",
       "      <td>-109.0</td>\n",
       "      <td>1600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>220</td>\n",
       "      <td>560</td>\n",
       "      <td>40.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>1600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>130</td>\n",
       "      <td>380</td>\n",
       "      <td>-50.0</td>\n",
       "      <td>-59.0</td>\n",
       "      <td>2500.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   m^2  Price  xi-x_mean  yi-y_mean  square(xi-x_mean)\n",
       "0  160    360      -20.0      -79.0              400.0\n",
       "1  150    340      -30.0      -99.0              900.0\n",
       "2  280    664      100.0      225.0            10000.0\n",
       "3  140    330      -40.0     -109.0             1600.0\n",
       "4  220    560       40.0      121.0             1600.0\n",
       "5  130    380      -50.0      -59.0             2500.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "houses['square(xi-x_mean)'] = houses['xi-x_mean']**2\n",
    "houses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`a.5`__ Create a new column in your dataset 'houses' named as __(xi-x_mean)(yi-y_mean)__ that will be equal to $( x_{i}-\\bar{x})( y_{i}-\\bar{y})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>m^2</th>\n",
       "      <th>Price</th>\n",
       "      <th>xi-x_mean</th>\n",
       "      <th>yi-y_mean</th>\n",
       "      <th>square(xi-x_mean)</th>\n",
       "      <th>(xi-x_mean)(yi-y_mean)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>160</td>\n",
       "      <td>360</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>-79.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>1580.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>150</td>\n",
       "      <td>340</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>900.0</td>\n",
       "      <td>2970.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>280</td>\n",
       "      <td>664</td>\n",
       "      <td>100.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>22500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>140</td>\n",
       "      <td>330</td>\n",
       "      <td>-40.0</td>\n",
       "      <td>-109.0</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>4360.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>220</td>\n",
       "      <td>560</td>\n",
       "      <td>40.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>4840.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>130</td>\n",
       "      <td>380</td>\n",
       "      <td>-50.0</td>\n",
       "      <td>-59.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>2950.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   m^2  Price  xi-x_mean  yi-y_mean  square(xi-x_mean)  (xi-x_mean)(yi-y_mean)\n",
       "0  160    360      -20.0      -79.0              400.0                  1580.0\n",
       "1  150    340      -30.0      -99.0              900.0                  2970.0\n",
       "2  280    664      100.0      225.0            10000.0                 22500.0\n",
       "3  140    330      -40.0     -109.0             1600.0                  4360.0\n",
       "4  220    560       40.0      121.0             1600.0                  4840.0\n",
       "5  130    380      -50.0      -59.0             2500.0                  2950.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "houses['(xi-x_mean)(yi-y_mean)'] = houses['xi-x_mean']*houses['yi-y_mean']\n",
    "houses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`a.6`__ Calculate the coefficient of 'm^2' by using the formula below and assign it to the object __beta1__ <br> <br>\n",
    "$$\\beta _{1} = \\frac{\\sum \\left ( x_{i}-\\bar{x})( y_{i}-\\bar{y}\\right )}{\\sum ( x_{i}-\\bar{x})^{2}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.3058823529411763"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta1 = houses['(xi-x_mean)(yi-y_mean)'].sum()/houses['square(xi-x_mean)'].sum()\n",
    "beta1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`a.7`__ Calculate the intercept and name it as __beta0__ by using the formula <br><br>\n",
    "\n",
    "$$\\beta _{0} = \\bar{y} - \\beta _{1}\\bar{x} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23.94117647058829"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta0 = mean_price - beta1*mean_m2\n",
    "beta0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`a.8`__ Predict the price of a house with $190m^{2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "462.05882352941177"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = beta0 + beta1*190\n",
    "prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Evaluate the Model <a name=\"4th-bullet\"></a>\n",
    "\n",
    "We predicted the price for a 190 mÂ² house using the manually computed coefficients. Now we visualise the fit (scatter and fitted line) and discuss the fit quality informally. We will use the Boston dataset example later for quantitative evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot your regression!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = houses['m^2']\n",
    "y = houses['Price']\n",
    "predictions = []\n",
    "\n",
    "for value in X:\n",
    "    predictions.append(beta0 + beta1*value)\n",
    "\n",
    "#create a figure with seaborn style\n",
    "fig = plt.figure()\n",
    "plt.plot(X, y, 'r.', markersize=12)\n",
    "plt.plot(X, predictions, 'b-')\n",
    "\n",
    "# add labels and title\n",
    "plt.xlabel('Size (mÂ²)')\n",
    "plt.ylabel('Price (1000s â¬)')\n",
    "plt.title('House Price vs Size with Regression Line')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, we have the data points and the regression line that we have just calculated. Intuitively, the line seems to fit the data relatively well, but to get a better sense of how well, we can compute evaluation metrics:\n",
    "\n",
    "a.9 Calculate the Mean Absolute Error (MAE) and name it as __mae__ using the formula below:<br><br>\n",
    "$$ MAE = \\frac{1}{n} \\sum_{i=1}^{n} |y_i - \\hat{y}_i| $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28.352941176470598"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae = np.mean(np.abs(houses['Price'] - predictions))\n",
    "mae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Scikt-Learn Implementation** <a name=\"5th-bullet\"></a>\n",
    "\n",
    "Now that we have built some intuition by calculating the coefficients manually, let's see how to implement linear regression using the `scikit-learn` library. Since we are dealing with linear regression, we are going to work with a dataset where the target is continuous. We will use the Boston housing dataset for this purpose.<br>\n",
    "\n",
    "### 2. Import the dataset <a name=\"6th-bullet\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "__`Step 2.1`__ - Import the dataset __Boston.csv__ using pandas and assign it to an object named __data__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Load a Real Dataset <a name=\"6th-bullet\"></a>\n",
    "\n",
    "We load the Boston housing dataset to practice a full scikit-learn workflow: preprocessing, train/validation split, fitting a LinearRegression model, and evaluating performance. The target variable is `medv` (median value of homes in $1000's)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crim</th>\n",
       "      <th>zn</th>\n",
       "      <th>indus</th>\n",
       "      <th>chas</th>\n",
       "      <th>nox</th>\n",
       "      <th>rm</th>\n",
       "      <th>age</th>\n",
       "      <th>dis</th>\n",
       "      <th>rad</th>\n",
       "      <th>tax</th>\n",
       "      <th>ptratio</th>\n",
       "      <th>black</th>\n",
       "      <th>lstat</th>\n",
       "      <th>medv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      crim    zn  indus  chas    nox     rm   age     dis  rad  tax  ptratio  \\\n",
       "0  0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296     15.3   \n",
       "1  0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242     17.8   \n",
       "2  0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242     17.8   \n",
       "3  0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222     18.7   \n",
       "4  0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222     18.7   \n",
       "\n",
       "    black  lstat  medv  \n",
       "0  396.90   4.98  24.0  \n",
       "1  396.90   9.14  21.6  \n",
       "2  392.83   4.03  34.7  \n",
       "3  394.63   2.94  33.4  \n",
       "4  396.90   5.33  36.2  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('datasets/Boston.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variables:<br>\n",
    "\n",
    "`INPUT VARIABLES`: numerical <br>\n",
    "`OUPUT VARIABLE`: numeric (regression) <br>\n",
    "\n",
    "__GOAL__: Predict median value of homes\n",
    "\n",
    "`CRIM` : per capita crime rate by town <br>\n",
    "`ZN` : proportion of residential land zoned for lots over 25,000 sq.ft. <br>\n",
    "`INDUS` : proportion of non-retail business acres per town. <br>\n",
    "`CHAS`: Charles River dummy variable (1 if tract bounds river; 0 otherwise) <br>\n",
    "`NOX` : nitric oxides concentration (parts per 10 million) <br>\n",
    "`RM`: average number of rooms per dwelling <br>\n",
    "`AGE`: proportion of owner-occupied units built prior to 1940 <br>\n",
    "`DIS`: weighted distances to five Boston employment centres <br>\n",
    "`RAD`: index of accessibility to radial highways <br>\n",
    "`TAX`: full-value property-tax rate per \\$10.000 <br>\n",
    "`PTRATIO`: pupil-teacher ratio by town <br>\n",
    "`B`: 1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town <br>\n",
    "`LSTAT`: % lower status of the population <br>\n",
    "`MEDV`: Median value of owner-occupied homes in $1000's <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Preprocess the Data <a name=\"7th-bullet\"></a>\n",
    "\n",
    "Placeholder: common preprocessing steps include handling missing values, scaling features, and encoding categorical variables. For the Boston dataset we will confirm there are no missing values and then consider scaling the features before fitting linear models. Add any dataset-specific preprocessing here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Explore the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to explore our data: while this is not the focus for this class, we are just going to check if we don't have missing values and what is the type of data that we have."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 2.2`__ - Call the method __info()__ in your data. <br>\n",
    "This method prints information about a DataFrame including the index dtype and column dtypes, non-null values and memory usage. <br>\n",
    "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.info.html?highlight=info#pandas.DataFrame.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 506 entries, 0 to 505\n",
      "Data columns (total 14 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   crim     506 non-null    float64\n",
      " 1   zn       506 non-null    float64\n",
      " 2   indus    506 non-null    float64\n",
      " 3   chas     506 non-null    int64  \n",
      " 4   nox      506 non-null    float64\n",
      " 5   rm       506 non-null    float64\n",
      " 6   age      506 non-null    float64\n",
      " 7   dis      506 non-null    float64\n",
      " 8   rad      506 non-null    int64  \n",
      " 9   tax      506 non-null    int64  \n",
      " 10  ptratio  506 non-null    float64\n",
      " 11  black    506 non-null    float64\n",
      " 12  lstat    506 non-null    float64\n",
      " 13  medv     506 non-null    float64\n",
      "dtypes: float64(11), int64(3)\n",
      "memory usage: 55.5 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By calling the __info()__ method, we can verify that we don't have missing values and all data is numerical, so there is no need to deal with missing data or create dummies. <br>\n",
    "We are ready to apply linear regression in our dataset! But first, and since we want to evaluate the performance of our model, we need to split our dataset into training and validation. Since we only have 506 observations, we are not going to create a test dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Data partition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 2.3`__ - By calling the method __train_test_split()__, split your dataset into train (70%) and validation (30%). Don't forget that you need to define first what are your independent variables and your target/ dependent variable. <br>\n",
    "\n",
    "- Define as __X__ the independent variables and __y__ the dependent variable (last column - 'medv')\n",
    "- Divide the __X__ into __X_train__ and __X_val__, the __y__ into __y_train__ and __y_val__, and define the following arguments: __test_size = 0.3__, __random_state = 15__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(columns=['medv'])\n",
    "y = data['medv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, \n",
    "                                                  test_size=0.3, \n",
    "                                                  random_state=33) #since we are dealing with regression, we do not need to stratify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Fit the Model <a name=\"8th-bullet\"></a>\n",
    "\n",
    "__`Step 2.4`__ - Create an instance of LinearRegression named as lin_model with the default parameters and fit to your train data. We'll fit on `X_train` / `y_train`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_model = LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <b><h3>Methods in LinearRegression()</h3></b><br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<a href = 'https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html'>sklearn.linear_model.LinearRegression().fit(X,y,...)</a>\n",
    "\n",
    "__Definition:__ <br>\n",
    "Fit linear model in the training data.\n",
    "\n",
    "__Parameters:__ <br>\n",
    "X : The regressors in my training dataset; <br>\n",
    "y : The target in my training dataset; <br>\n",
    "...\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 2.5`__ - Fit your model to your data, and define __X = X_train__ and __y = y_train__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"â¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â¾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<a href = 'https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html'>sklearn.linear_model.LinearRegression().predict(X)</a>\n",
    "\n",
    "__Definition:__ <br>\n",
    "Predict using the linear model.\n",
    "\n",
    "__Parameters:__ <br>\n",
    "X : Samples to predict; <br>\n",
    "...\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 2.6`__ - Predict the values for __X_val__ by applying the method __predict()__ to your model and check your result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([20.26132887, 11.12890007, 13.82627828, 18.13795816, 22.74068948,\n",
       "       20.81362135, 37.06672084, 14.57964237, 23.18047766, 22.29283728,\n",
       "       25.30760875, 37.28366292,  5.26162191, 25.54689587, 11.14149317,\n",
       "       23.86701965, 17.53621385, 19.22877681, 32.30964337, 22.46328135,\n",
       "       13.66494099, 19.84901793, 18.33905479, 18.58967918, 34.21945675,\n",
       "       15.5474774 , 25.68842945, 25.01817805, 11.611136  , 34.6951032 ,\n",
       "       16.40332985, 25.7936335 ,  4.9636998 , 15.87579626, 30.22113715,\n",
       "       34.01330171, 25.36639356,  5.0435889 , 20.0914974 , 29.24920209,\n",
       "       17.66206447, 13.68787519, 30.35709343, 15.74004133, 30.31485688,\n",
       "       20.30855375, 21.86998166, 17.2791456 , 24.09261766, 21.15547882,\n",
       "       17.34757262, 36.12785159, 10.52813864, 16.39129236, 24.76060752,\n",
       "       14.05706367, 25.14308632, 15.23217452, 22.53938422, 23.78169103,\n",
       "       16.895084  , 18.79193305, 35.81800064, 22.20600093, 17.97053995,\n",
       "       25.29602065, 28.39118047, -0.76151906, 13.54367738, 30.23317118,\n",
       "       21.44969315, 19.21873556, 15.18987127, 22.04015957, 16.67041618,\n",
       "       39.35534385, 20.16754422,  2.42231563, 17.8281064 , 25.37281703,\n",
       "       21.22199636,  8.29382117, 17.54022434, 20.07818522, 22.34891637,\n",
       "       20.98677968, 42.85249522, 15.7161652 , 45.87815699, 33.36757182,\n",
       "       31.20712278, 19.34172573, 10.29756432, 14.63825582, 14.11102789,\n",
       "       30.80656984, 22.47742664, 25.397893  , 16.73034628, 19.73853857,\n",
       "       14.92565857, 20.64863438, 31.88379069, 26.93982264, 10.44987161,\n",
       "       12.5677274 ,  5.6904935 , 28.96842323, 14.22405056, 28.22062219,\n",
       "       24.94483167, 13.7489487 , 13.68368907, 24.22924631, 28.22501503,\n",
       "       23.57180616, 25.01101927, 22.68589272, 30.52089161, 20.44936251,\n",
       "       25.84540029, 19.59862074, 15.67801446, 23.0962855 , 23.21757629,\n",
       "       14.52911225, 36.56059803, 35.5954372 , 21.91753887,  5.53844299,\n",
       "       26.99411365, 22.14860955, 25.2081702 , 32.55106885, 22.99691069,\n",
       "       20.75262952, 30.1574721 , 27.54154807, 20.27991963, 23.09044091,\n",
       "       16.50454276, 13.06382449, 35.62346614, 33.11178898, 16.35891616,\n",
       "       19.53102961, 36.31788441, 14.91988312, 12.26129461, 13.04379038,\n",
       "       21.02587202, 26.50007893])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = lin_model.predict(X_val)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 2.7`__ - Create a Dataset named*results* with two columns: the real values (__y_val__) and the predicted values (__y_pred__)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_true</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>20.5</td>\n",
       "      <td>20.261329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>5.6</td>\n",
       "      <td>11.128900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>13.4</td>\n",
       "      <td>13.826278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>12.6</td>\n",
       "      <td>18.137958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>21.2</td>\n",
       "      <td>22.740689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>20.1</td>\n",
       "      <td>14.919883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>10.5</td>\n",
       "      <td>12.261295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>15.6</td>\n",
       "      <td>13.043790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>16.8</td>\n",
       "      <td>21.025872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>22.6</td>\n",
       "      <td>26.500079</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>152 rows Ã 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     y_true     y_pred\n",
       "122    20.5  20.261329\n",
       "400     5.6  11.128900\n",
       "423    13.4  13.826278\n",
       "447    12.6  18.137958\n",
       "44     21.2  22.740689\n",
       "..      ...        ...\n",
       "492    20.1  14.919883\n",
       "440    10.5  12.261295\n",
       "134    15.6  13.043790\n",
       "363    16.8  21.025872\n",
       "174    22.6  26.500079\n",
       "\n",
       "[152 rows x 2 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_results = pd.DataFrame({'y_true': y_val.values.flatten(), 'y_pred': predictions.flatten()}, \n",
    "                           index=y_val.index #ensures we can map the predictions to each observation correctly\n",
    "                           )\n",
    "val_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have predicted the values for our validation dataset, we need to evaluate the performance of our model. Since we are dealing with regression, we are going to use the following metrics: Mean Absolute Error (MAE) and $R^2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training metrics:\n",
      "RÂ²: 0.7541\n",
      "MAE: 3.2887\n"
     ]
    }
   ],
   "source": [
    "# Training metrics (step 2)\n",
    "y_pred_train = lin_model.predict(X_train)\n",
    "r2_train = r2_score(y_train, y_pred_train)\n",
    "mae_train = mean_absolute_error(y_train, y_pred_train)\n",
    "\n",
    "print('Training metrics:')\n",
    "print(f'RÂ²: {r2_train:.4f}')\n",
    "print(f'MAE: {mae_train:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation metrics:\n",
      "RÂ²: 0.6846\n",
      "MAE: 3.4397\n"
     ]
    }
   ],
   "source": [
    "# Validation metrics (step 1)\n",
    "r2_val = r2_score(y_val, predictions)\n",
    "mae_val = mean_absolute_error(y_val, predictions)\n",
    "\n",
    "print('Validation metrics:')\n",
    "print(f'RÂ²: {r2_val:.4f}') #-> possible overfitting as R^2 val < R^2 val test (might be: too much variables)\n",
    "print(f'MAE: {mae_val:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Evaluate the Model <a name=\"9th-bullet\"></a>\n",
    "\n",
    "Placeholder: after predicting on `X_val`, compute metrics such as RÂ², Adjusted RÂ², MSE and MAE. Use sklearn.metrics (r2_score, mean_squared_error, mean_absolute_error) to report validation performance and compare with training metrics to check for overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Those are the predicted values to your validation dataset by applying the model created previously based on train data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <b><h3>Attributes in LinearRegression()</h3></b><br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<a href = 'https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html'>sklearn.linear_model.LinearRegression().coef_</a>\n",
    "\n",
    "__Definition:__ <br>\n",
    "Coefficient of the features in the decision function.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 2.7`__ - To check the coefficients calculated by applying the linear regression, call the attribute __coef___ associated to your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.26344270e-01,  4.92843878e-02, -6.72157053e-04,  3.18525778e+00,\n",
       "       -1.46742932e+01,  4.12294308e+00, -5.78913516e-03, -1.57407880e+00,\n",
       "        3.34624794e-01, -1.42107385e-02, -9.17844246e-01,  6.43121442e-03,\n",
       "       -5.51108318e-01])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_model.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is an array that shows all the coefficients. In order to better understand what is the variable associated to each coefficient, let's convert the result to a DataFrame and define as headers the variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 2.8`__ - Create a dataframe that will contain the values of the coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.126344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.049284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.000672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.185258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-14.674293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.122943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.005789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-1.574079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.334625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.014211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.917844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.006431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.551108</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0\n",
       "0   -0.126344\n",
       "1    0.049284\n",
       "2   -0.000672\n",
       "3    3.185258\n",
       "4  -14.674293\n",
       "5    4.122943\n",
       "6   -0.005789\n",
       "7   -1.574079\n",
       "8    0.334625\n",
       "9   -0.014211\n",
       "10  -0.917844\n",
       "11   0.006431\n",
       "12  -0.551108"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coefs = pd.DataFrame(lin_model.coef_)\n",
    "coefs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 2.9`__ - By using the method __set_index()__, define the index of Dataframe equal to the name of the variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>crim</th>\n",
       "      <td>-0.126344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zn</th>\n",
       "      <td>0.049284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>indus</th>\n",
       "      <td>-0.000672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chas</th>\n",
       "      <td>3.185258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nox</th>\n",
       "      <td>-14.674293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rm</th>\n",
       "      <td>4.122943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>-0.005789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dis</th>\n",
       "      <td>-1.574079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rad</th>\n",
       "      <td>0.334625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tax</th>\n",
       "      <td>-0.014211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ptratio</th>\n",
       "      <td>-0.917844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>black</th>\n",
       "      <td>0.006431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lstat</th>\n",
       "      <td>-0.551108</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0\n",
       "crim     -0.126344\n",
       "zn        0.049284\n",
       "indus    -0.000672\n",
       "chas      3.185258\n",
       "nox     -14.674293\n",
       "rm        4.122943\n",
       "age      -0.005789\n",
       "dis      -1.574079\n",
       "rad       0.334625\n",
       "tax      -0.014211\n",
       "ptratio  -0.917844\n",
       "black     0.006431\n",
       "lstat    -0.551108"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coefs = coefs.set_index(X_train.columns)\n",
    "coefs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<a href = 'https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html'>sklearn.linear_model.LinearRegression().intercept_</a>\n",
    "\n",
    "__Definition:__ <br>\n",
    "Independent term in the linear model.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 2.10`__ - To obtain the intercept of the linear regression, call the attribute __intercept___ associated to your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35.04496345263828"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The intercept (often labeled the constant) is the expected mean value of Y when all X=0.\n",
    "lin_model.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\"> \n",
    "<h1><center>Calculate the p-values</center></h1>\n",
    "</div>\n",
    "\n",
    "<a name=\"10th-bullet\"></a>\n",
    "\n",
    "For descriptive/interpretability purposes, it may be useful to obtain inference statistics (standard errors, t-values, p-values) using `statsmodels`. We will use this library because `sklearn` does not provide this information directly and other libraries that would provide this information are not very well maintained (e.g. the package `regressors`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sklearn intercept and coefficients:\n",
      "Intercept    35.044963\n",
      "crim         -0.126344\n",
      "zn            0.049284\n",
      "indus        -0.000672\n",
      "chas          3.185258\n",
      "nox         -14.674293\n",
      "rm            4.122943\n",
      "age          -0.005789\n",
      "dis          -1.574079\n",
      "rad           0.334625\n",
      "tax          -0.014211\n",
      "ptratio      -0.917844\n",
      "black         0.006431\n",
      "lstat        -0.551108\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Compare with sklearn coefficients\n",
    "sk_coef = np.concatenate(([lin_model.intercept_], np.asarray(lin_model.coef_).ravel()))\n",
    "print('\\nSklearn intercept and coefficients:')\n",
    "print(pd.Series(sk_coef, index=['Intercept'] + list(X_train.columns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Create a Separate Model using Statsmodels<a name=\"11th-bullet\"></a>\n",
    "\n",
    "For multivariate linear regression, we tend to use `sklearn` because of the familiarity its syntax has with the one used in other algorithms. However, interpretability-wise, `sklearn` only allows us to access the coefficients. Other packages have the ability to also create linear regressions (e.g. `numpy`, `scipy` or even `statsmodels.api`). Since the estimation method is the same (OLS), we can use `statsmodels` to obtain a full statistical summary of the fitted model, including standard errors, t-values, p-values, and confidence interval.\n",
    "\n",
    "### 3.2 Extract p-values / alternatives <a name=\"12th-bullet\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Alternatives to the `regressors` package\n",
    "\n",
    "`scikit-learn` does not provide p-values or standard errors out of the box. If you need inference statistics there are three practical options:\n",
    "\n",
    "- Use `statsmodels.api.OLS` which gives a full statistical summary (p-values, SEs, t-stats, etc.).\n",
    "- Compute standard errors and p-values manually from the fitted `LinearRegression` object and the design matrix (example helper can be provided so you keep a scikit-learn friendly workflow)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                   medv   R-squared:                       0.754\n",
      "Model:                            OLS   Adj. R-squared:                  0.745\n",
      "Method:                 Least Squares   F-statistic:                     80.19\n",
      "Date:                Wed, 15 Oct 2025   Prob (F-statistic):           4.21e-95\n",
      "Time:                        11:58:55   Log-Likelihood:                -1048.7\n",
      "No. Observations:                 354   AIC:                             2125.\n",
      "Df Residuals:                     340   BIC:                             2179.\n",
      "Df Model:                          13                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         35.0450      6.091      5.754      0.000      23.065      47.025\n",
      "crim          -0.1263      0.039     -3.224      0.001      -0.203      -0.049\n",
      "zn             0.0493      0.016      3.072      0.002       0.018       0.081\n",
      "indus         -0.0007      0.072     -0.009      0.993      -0.143       0.142\n",
      "chas           3.1853      1.030      3.091      0.002       1.158       5.212\n",
      "nox          -14.6743      4.782     -3.069      0.002     -24.080      -5.269\n",
      "rm             4.1229      0.491      8.389      0.000       3.156       5.090\n",
      "age           -0.0058      0.016     -0.368      0.713      -0.037       0.025\n",
      "dis           -1.5741      0.247     -6.379      0.000      -2.059      -1.089\n",
      "rad            0.3346      0.084      4.004      0.000       0.170       0.499\n",
      "tax           -0.0142      0.005     -3.026      0.003      -0.023      -0.005\n",
      "ptratio       -0.9178      0.155     -5.931      0.000      -1.222      -0.613\n",
      "black          0.0064      0.004      1.804      0.072      -0.001       0.013\n",
      "lstat         -0.5511      0.060     -9.235      0.000      -0.668      -0.434\n",
      "==============================================================================\n",
      "Omnibus:                      136.257   Durbin-Watson:                   1.869\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              541.554\n",
      "Skew:                           1.658   Prob(JB):                    2.53e-118\n",
      "Kurtosis:                       8.071   Cond. No.                     1.49e+04\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.49e+04. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "# Statsmodels (full statistical summary)\n",
    "import statsmodels.api as sm\n",
    "X_sm = sm.add_constant(X_train)\n",
    "ols = sm.OLS(y_train, X_sm).fit()\n",
    "print(ols.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The summary statistic table calls many of the stats outputs the statistics in an pretty format, containing all the needed values to interpret our model: The residuals distribution, the coefficients and the t-value and the p-value for each of them, and also the evaluation of the model using the metrics R-Squared, Adjusted R-Squared and F-statistic. That evaluation, however, is based on the performance of the model in the training dataset. <br> If you want to see how to compute these metrics for the validation data, in the last class we saw how to calculate the R-Squared and the Adjusted R-Squared to our validation dataset by using __sklearn__.\n",
    "\n",
    "__The p-value__ <br>\n",
    "For each estimated regression coefficient, the p-value provides an estimate of the probability that the true coefficient is zero given the value of the estimate. Small p-values suggest that the true coefficient is very unlikely to be zero, which means that the feature is extremely unlikely to have no relationship with the dependent variable. <br> In this way, we can also check the p-value to understand the feature importance and select the most \"important\" variables to build our final model.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Extra Material: Linear Regression Variants <a name=\"13th-bullet\"></a>\n",
    "\n",
    "Despite its simplicity, linear regression is a powerful algorithm that can be used as a baseline for regression tasks. However, it has some limitations, such as sensitivity to outliers and multicollinearity among predictors. To try to address these issues, there are variants of linear regression that add a penalty term to the loss function. In this notebook, we will show the implementations of 3: Ridge Regression (which uses L2 norm), Lasso Regression (which uses L1 norm), and Elastic Net (which uses both)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key Concept: How Regularization Changes the Optimization**\n",
    "\n",
    "All linear regression variants use the same **prediction formula**:\n",
    "$$\\hat{y} = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + ... + \\beta_p x_p$$\n",
    "\n",
    "The difference lies in **what we minimize** during training:\n",
    "\n",
    "| Method | Optimization Objective |\n",
    "|--------|----------------------|\n",
    "| **OLS** | $\\min_{\\beta} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2$ |\n",
    "| **Ridge** | $\\min_{\\beta} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2 + \\alpha \\sum_{j=1}^{p} \\beta_j^2$ |\n",
    "| **Lasso** | $\\min_{\\beta} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2 + \\alpha \\sum_{j=1}^{p} \\lvert\\beta_j\\rvert$ |\n",
    "| **Elastic Net** | $\\min_{\\beta} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2 + \\alpha \\left[ \\rho \\sum_{j=1}^{p} \\lvert\\beta_j\\rvert + \\frac{(1-\\rho)}{2} \\sum_{j=1}^{p} \\beta_j^2 \\right]$ |\n",
    "\n",
    "The **penalty terms** (everything after the sum of squared errors) control how large the coefficients can become, helping to prevent overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 Ridge Regression (L2 Regularization)\n",
    "\n",
    "Ridge regression adds an **L2 penalty** term to the loss function, which helps prevent overfitting by penalizing large coefficient values. This is particularly useful when dealing with multicollinearity.\n",
    "\n",
    "**OLS Prediction Formula (Standard Linear Regression):**\n",
    "$$\\hat{y} = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + ... + \\beta_p x_p$$\n",
    "\n",
    "**OLS Optimization (what we minimize):**\n",
    "$$\\min_{\\beta} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2$$\n",
    "\n",
    "**Ridge Optimization (with L2 penalty):**\n",
    "$$\\min_{\\beta} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2 + \\alpha \\sum_{j=1}^{p} \\beta_j^2$$\n",
    "\n",
    "**Key Difference:** Ridge adds the term $\\alpha \\sum_{j=1}^{p} \\beta_j^2$ which penalizes the **squared magnitude** of coefficients. This shrinks coefficients toward zero but never exactly to zero. Higher values of $\\alpha$ lead to more regularization (smaller coefficients)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<a href='https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html'>sklearn.linear_model.Ridge(alpha=1.0, fit_intercept=True, solver='auto')</a>\n",
    "\n",
    "__Definition:__ <br>\n",
    "Linear least squares with L2 regularization. Minimizes the residual sum of squares between observed targets and predicted targets plus a penalty term proportional to the squared L2 norm of the coefficient vector.\n",
    "\n",
    "__Key Parameters:__ <br>\n",
    "- `alpha`: Regularization strength; must be a positive float. Larger values specify stronger regularization (default=1.0). <br>\n",
    "- `fit_intercept`: Whether to calculate the intercept for this model (default=True). <br>\n",
    "- `solver`: Solver to use in the computational routines (default='auto'). <br>\n",
    "\n",
    "__Methods:__ <br>\n",
    "- `.fit(X, y)`: Fit Ridge regression model. <br>\n",
    "- `.predict(X)`: Predict using the linear model. <br>\n",
    "\n",
    "__Attributes:__ <br>\n",
    "- `.coef_`: Estimated coefficients for the linear regression problem. <br>\n",
    "- `.intercept_`: Independent term in the linear model. <br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Implementation:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Regression Results:\n",
      "Training RÂ²: 0.7523\n",
      "Validation RÂ²: 0.6756\n",
      "Training MAE: 3.30\n",
      "Validation MAE: 3.48\n",
      "\n",
      "Intercept: 30.45\n",
      "Coefficients:\n",
      "  crim: -0.1236\n",
      "  zn: 0.0508\n",
      "  indus: -0.0313\n",
      "  chas: 3.0363\n",
      "  nox: -7.3269\n",
      "  rm: 4.1309\n",
      "  age: -0.0113\n",
      "  dis: -1.4670\n",
      "  rad: 0.3225\n",
      "  tax: -0.0151\n",
      "  ptratio: -0.8445\n",
      "  black: 0.0066\n",
      "  lstat: -0.5630\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# Create Ridge regression model with alpha=1.0\n",
    "ridge_model = Ridge(alpha=1.0)\n",
    "\n",
    "# Fit the model\n",
    "ridge_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_ridge_train = ridge_model.predict(X_train)\n",
    "y_pred_ridge_val = ridge_model.predict(X_val)\n",
    "\n",
    "# Evaluate the model\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "\n",
    "print(\"Ridge Regression Results:\")\n",
    "print(f\"Training RÂ²: {r2_score(y_train, y_pred_ridge_train):.4f}\")\n",
    "print(f\"Validation RÂ²: {r2_score(y_val, y_pred_ridge_val):.4f}\")\n",
    "print(f\"Training MAE: {mean_absolute_error(y_train, y_pred_ridge_train):.2f}\")\n",
    "print(f\"Validation MAE: {mean_absolute_error(y_val, y_pred_ridge_val):.2f}\")\n",
    "print(f\"\\nIntercept: {ridge_model.intercept_:.2f}\")\n",
    "print(\"Coefficients:\")\n",
    "for feature, coef in zip(X_train.columns, ridge_model.coef_):\n",
    "    print(f\"  {feature}: {coef:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Lasso Regression (L1 Regularization)\n",
    "\n",
    "Lasso (Least Absolute Shrinkage and Selection Operator) uses an **L1 penalty** that can shrink some coefficients to exactly zero, effectively performing **feature selection**.\n",
    "\n",
    "**OLS Prediction Formula (Standard Linear Regression):**\n",
    "$$\\hat{y} = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + ... + \\beta_p x_p$$\n",
    "\n",
    "**OLS Optimization (what we minimize):**\n",
    "$$\\min_{\\beta} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2$$\n",
    "\n",
    "**Lasso Optimization (with L1 penalty):**\n",
    "$$\\min_{\\beta} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2 + \\alpha \\sum_{j=1}^{p} \\lvert\\beta_j\\rvert$$\n",
    "\n",
    "**Key Difference:** Lasso adds the term $\\alpha \\sum_{j=1}^{p} \\lvert\\beta_j\\rvert$ which penalizes the **absolute value** of coefficients. Unlike Ridge, this can force some coefficients to become **exactly zero**, thus performing automatic feature selection. This makes Lasso particularly useful for high-dimensional datasets where you want to identify the most important features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<a href='https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html'>sklearn.linear_model.Lasso(alpha=1.0, fit_intercept=True, max_iter=1000)</a>\n",
    "\n",
    "__Definition:__ <br>\n",
    "Linear Model trained with L1 prior as regularizer (aka the Lasso). The optimization objective minimizes the residual sum of squares with a penalty proportional to the L1 norm (absolute value) of the coefficient vector. This can lead to sparse models where some coefficients are exactly zero.\n",
    "\n",
    "__Key Parameters:__ <br>\n",
    "- `alpha`: Constant that multiplies the L1 term, controlling regularization strength (default=1.0). <br>\n",
    "- `fit_intercept`: Whether to calculate the intercept for this model (default=True). <br>\n",
    "- `max_iter`: Maximum number of iterations for the optimization algorithm (default=1000). <br>\n",
    "- `selection`: Method for updating coefficients - 'cyclic' or 'random' (default='cyclic'). <br>\n",
    "\n",
    "__Methods:__ <br>\n",
    "- `.fit(X, y)`: Fit Lasso regression model. <br>\n",
    "- `.predict(X)`: Predict using the linear model. <br>\n",
    "\n",
    "__Attributes:__ <br>\n",
    "- `.coef_`: Estimated coefficients (some may be exactly 0 if features are not selected). <br>\n",
    "- `.intercept_`: Independent term in the linear model. <br>\n",
    "- `.n_iter_`: Number of iterations run by the coordinate descent solver. <br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Implementation:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso Regression Results:\n",
      "Training RÂ²: 0.7028\n",
      "Validation RÂ²: 0.6635\n",
      "Training MAE: 3.59\n",
      "Validation MAE: 3.55\n",
      "\n",
      "Intercept: 42.66\n",
      "Coefficients:\n",
      "  crim: -0.0773\n",
      "  zn: 0.0493\n",
      "  indus: -0.0000\n",
      "  chas: 0.0000\n",
      "  nox: -0.0000\n",
      "  rm: 1.2837\n",
      "  age: 0.0208\n",
      "  dis: -0.7796\n",
      "  rad: 0.3119\n",
      "  tax: -0.0177\n",
      "  ptratio: -0.8120\n",
      "  black: 0.0061\n",
      "  lstat: -0.7797\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "# Create Lasso regression model with alpha=1.0\n",
    "lasso_model = Lasso(alpha=1.0, max_iter=10000)\n",
    "\n",
    "# Fit the model\n",
    "lasso_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_lasso_train = lasso_model.predict(X_train)\n",
    "y_pred_lasso_val = lasso_model.predict(X_val)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Lasso Regression Results:\")\n",
    "print(f\"Training RÂ²: {r2_score(y_train, y_pred_lasso_train):.4f}\")\n",
    "print(f\"Validation RÂ²: {r2_score(y_val, y_pred_lasso_val):.4f}\")\n",
    "print(f\"Training MAE: {mean_absolute_error(y_train, y_pred_lasso_train):.2f}\")\n",
    "print(f\"Validation MAE: {mean_absolute_error(y_val, y_pred_lasso_val):.2f}\")\n",
    "print(f\"\\nIntercept: {lasso_model.intercept_:.2f}\")\n",
    "print(\"Coefficients:\")\n",
    "for feature, coef in zip(X_train.columns, lasso_model.coef_):\n",
    "    print(f\"  {feature}: {coef:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 Elastic Net Regression (L1 + L2 Regularization)\n",
    "\n",
    "Elastic Net combines both **L1 and L2 penalties**, providing a balance between Ridge and Lasso. It's particularly useful when there are multiple correlated features.\n",
    "\n",
    "**OLS Prediction Formula (Standard Linear Regression):**\n",
    "$$\\hat{y} = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + ... + \\beta_p x_p$$\n",
    "\n",
    "**OLS Optimization (what we minimize):**\n",
    "$$\\min_{\\beta} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2$$\n",
    "\n",
    "**Elastic Net Optimization (with combined L1 + L2 penalty):**\n",
    "$$\\min_{\\beta} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2 + \\alpha \\left[ \\rho \\sum_{j=1}^{p} \\lvert\\beta_j\\rvert + \\frac{(1-\\rho)}{2} \\sum_{j=1}^{p} \\beta_j^2 \\right]$$\n",
    "\n",
    "**Key Difference:** Elastic Net adds a **weighted combination** of both L1 and L2 penalties:\n",
    "- $\\alpha$ controls the overall regularization strength\n",
    "- $\\rho$ (l1_ratio) controls the mix between L1 and L2:\n",
    "  - $\\rho = 0$: Pure Ridge (L2 only)\n",
    "  - $\\rho = 1$: Pure Lasso (L1 only)\n",
    "  - $0 < \\rho < 1$: Combination of both\n",
    "\n",
    "This combines Ridge's ability to handle correlated features with Lasso's feature selection capability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<a href='https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ElasticNet.html'>sklearn.linear_model.ElasticNet(alpha=1.0, l1_ratio=0.5, fit_intercept=True, max_iter=1000)</a>\n",
    "\n",
    "__Definition:__ <br>\n",
    "Linear regression with combined L1 and L2 priors as regularizer. The optimization objective minimizes the residual sum of squares with a penalty that is a combination of both L1 (Lasso) and L2 (Ridge) regularization terms. Useful when there are multiple features correlated with each other.\n",
    "\n",
    "__Key Parameters:__ <br>\n",
    "- `alpha`: Constant that multiplies the penalty terms (default=1.0). <br>\n",
    "- `l1_ratio`: The ElasticNet mixing parameter, with 0 <= l1_ratio <= 1 (default=0.5). <br>\n",
    "  - For l1_ratio = 0, the penalty is an L2 penalty (Ridge). <br>\n",
    "  - For l1_ratio = 1, it is an L1 penalty (Lasso). <br>\n",
    "  - For 0 < l1_ratio < 1, the penalty is a combination of L1 and L2. <br>\n",
    "- `fit_intercept`: Whether to calculate the intercept (default=True). <br>\n",
    "- `max_iter`: Maximum number of iterations (default=1000). <br>\n",
    "\n",
    "__Methods:__ <br>\n",
    "- `.fit(X, y)`: Fit ElasticNet model. <br>\n",
    "- `.predict(X)`: Predict using the linear model. <br>\n",
    "\n",
    "__Attributes:__ <br>\n",
    "- `.coef_`: Estimated coefficients for the linear regression problem. <br>\n",
    "- `.intercept_`: Independent term in the linear model. <br>\n",
    "- `.n_iter_`: Number of iterations run by the coordinate descent solver. <br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Implementation:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elastic Net Regression Results:\n",
      "Training RÂ²: 0.7016\n",
      "Validation RÂ²: 0.6592\n",
      "Training MAE: 3.60\n",
      "Validation MAE: 3.59\n",
      "\n",
      "Intercept: 45.19\n",
      "Coefficients:\n",
      "  crim: -0.0935\n",
      "  zn: 0.0538\n",
      "  indus: -0.0191\n",
      "  chas: 0.0000\n",
      "  nox: -0.0000\n",
      "  rm: 1.0546\n",
      "  age: 0.0227\n",
      "  dis: -0.8614\n",
      "  rad: 0.3550\n",
      "  tax: -0.0190\n",
      "  ptratio: -0.8377\n",
      "  black: 0.0062\n",
      "  lstat: -0.7888\n",
      "\n",
      "Features selected: 11 out of 13\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "# Create Elastic Net model with alpha=1.0 and l1_ratio=0.5 (equal mix of L1 and L2)\n",
    "elastic_model = ElasticNet(alpha=1.0, l1_ratio=0.5, max_iter=10000)\n",
    "\n",
    "# Fit the model\n",
    "elastic_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_elastic_train = elastic_model.predict(X_train)\n",
    "y_pred_elastic_val = elastic_model.predict(X_val)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Elastic Net Regression Results:\")\n",
    "print(f\"Training RÂ²: {r2_score(y_train, y_pred_elastic_train):.4f}\")\n",
    "print(f\"Validation RÂ²: {r2_score(y_val, y_pred_elastic_val):.4f}\")\n",
    "print(f\"Training MAE: {mean_absolute_error(y_train, y_pred_elastic_train):.2f}\")\n",
    "print(f\"Validation MAE: {mean_absolute_error(y_val, y_pred_elastic_val):.2f}\")\n",
    "print(f\"\\nIntercept: {elastic_model.intercept_:.2f}\")\n",
    "print(\"Coefficients:\")\n",
    "for feature, coef in zip(X_train.columns, elastic_model.coef_):\n",
    "    print(f\"  {feature}: {coef:.4f}\")\n",
    "    \n",
    "# Count how many features were selected (non-zero coefficients)\n",
    "n_features_selected = sum(elastic_model.coef_ != 0)\n",
    "print(f\"\\nFeatures selected: {n_features_selected} out of {len(elastic_model.coef_)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.4 Comparing All Models\n",
    "\n",
    "Let's compare the performance of all four models (OLS, Ridge, Lasso, and Elastic Net) side by side:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Comparison:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Train RÂ²</th>\n",
       "      <th>Val RÂ²</th>\n",
       "      <th>Train MAE</th>\n",
       "      <th>Val MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OLS (sklearn)</td>\n",
       "      <td>0.754060</td>\n",
       "      <td>0.684585</td>\n",
       "      <td>3.288689</td>\n",
       "      <td>3.439723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>0.752332</td>\n",
       "      <td>0.675550</td>\n",
       "      <td>3.295314</td>\n",
       "      <td>3.479771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>0.702805</td>\n",
       "      <td>0.663480</td>\n",
       "      <td>3.586822</td>\n",
       "      <td>3.550381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Elastic Net</td>\n",
       "      <td>0.701611</td>\n",
       "      <td>0.659179</td>\n",
       "      <td>3.596005</td>\n",
       "      <td>3.593509</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Model  Train RÂ²    Val RÂ²  Train MAE   Val MAE\n",
       "0  OLS (sklearn)  0.754060  0.684585   3.288689  3.439723\n",
       "1          Ridge  0.752332  0.675550   3.295314  3.479771\n",
       "2          Lasso  0.702805  0.663480   3.586822  3.550381\n",
       "3    Elastic Net  0.701611  0.659179   3.596005  3.593509"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create comparison dataframe\n",
    "comparison = pd.DataFrame({\n",
    "    'Model': ['OLS (sklearn)', 'Ridge', 'Lasso', 'Elastic Net'],\n",
    "    'Train RÂ²': [\n",
    "        r2_score(y_train, y_pred_train),\n",
    "        r2_score(y_train, y_pred_ridge_train),\n",
    "        r2_score(y_train, y_pred_lasso_train),\n",
    "        r2_score(y_train, y_pred_elastic_train)\n",
    "    ],\n",
    "    'Val RÂ²': [\n",
    "        r2_score(y_val, lin_model.predict(X_val)),\n",
    "        r2_score(y_val, y_pred_ridge_val),\n",
    "        r2_score(y_val, y_pred_lasso_val),\n",
    "        r2_score(y_val, y_pred_elastic_val)\n",
    "    ],\n",
    "    'Train MAE': [\n",
    "        mean_absolute_error(y_train, y_pred_train),\n",
    "        mean_absolute_error(y_train, y_pred_ridge_train),\n",
    "        mean_absolute_error(y_train, y_pred_lasso_train),\n",
    "        mean_absolute_error(y_train, y_pred_elastic_train)\n",
    "    ],\n",
    "    'Val MAE': [\n",
    "        mean_absolute_error(y_val, lin_model.predict(X_val)),\n",
    "        mean_absolute_error(y_val, y_pred_ridge_val),\n",
    "        mean_absolute_error(y_val, y_pred_lasso_val),\n",
    "        mean_absolute_error(y_val, y_pred_elastic_val)\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"Model Comparison:\")\n",
    "comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.5 Summary and Best Practices\n",
    "\n",
    "**When to use each variant:**\n",
    "\n",
    "1. **Ordinary Least Squares (OLS):**\n",
    "   - Good baseline model\n",
    "   - Use when you have few features relative to samples\n",
    "   - Interpretability is important\n",
    "   - No multicollinearity issues\n",
    "\n",
    "2. **Ridge Regression (L2):**\n",
    "   - When you have multicollinearity (correlated features)\n",
    "   - You want to keep all features but reduce their magnitude\n",
    "   - Prevents overfitting by shrinking coefficients\n",
    "\n",
    "3. **Lasso Regression (L1):**\n",
    "   - When you need feature selection (automatic variable selection)\n",
    "   - High-dimensional datasets with many irrelevant features\n",
    "   - Want a sparse model (some coefficients exactly zero)\n",
    "\n",
    "4. **Elastic Net:**\n",
    "   - Best of both worlds: handles multicollinearity AND performs feature selection\n",
    "   - When you have many correlated features\n",
    "   - More stable than Lasso when features are highly correlated\n",
    "   - Good default choice for regularized regression\n",
    "\n",
    "**General Tips:**\n",
    "- Always standardize/normalize features before applying regularization\n",
    "- Start with Elastic Net if unsure which regularization to use\n",
    "- Compare validation performance,\n",
    "\n",
    "**Visual Summary:**\n",
    "\n",
    "| Method | Penalty Type | Feature Selection | Handles Multicollinearity | Coefficients Can Be Zero |\n",
    "|--------|-------------|-------------------|---------------------------|-------------------------|\n",
    "| OLS | None | No | No | No |\n",
    "| Ridge (L2) | $\\sum \\beta_j^2$ | No | Yes | No (shrink toward 0) |\n",
    "| Lasso (L1) | $\\sum \\lvert\\beta_j\\rvert$ | Yes | Partially | Yes (exactly 0) |\n",
    "| Elastic Net | L1 + L2 | Yes | Yes | Yes (exactly 0) |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
